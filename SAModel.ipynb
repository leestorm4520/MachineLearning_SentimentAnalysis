{"cells":[{"cell_type":"code","execution_count":87,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":376,"status":"ok","timestamp":1636086326768,"user":{"displayName":"Jack xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNUlNXY1CX3VYFSRl25LPymi5g8mOLu96mwvQm=s64","userId":"14262939990159303181"},"user_tz":300},"id":"t9afIFJA2jJ8","outputId":"27d6824f-347f-4af9-e004-fb37e87f9209"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     /Users/johnle/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /Users/johnle/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["\n","import pandas as pd\n","import re\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import StandardScaler\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.utils import shuffle\n","from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score\n","import string \n","\n"]},{"cell_type":"markdown","metadata":{"id":"8CfASqL76-TC"},"source":["turning all uppercase to lower\n"]},{"cell_type":"code","execution_count":54,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1636086326769,"user":{"displayName":"Jack xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNUlNXY1CX3VYFSRl25LPymi5g8mOLu96mwvQm=s64","userId":"14262939990159303181"},"user_tz":300},"id":"6v0app4ghE6p"},"outputs":[],"source":["creat_sentance = WordNetLemmatizer()"]},{"cell_type":"code","execution_count":55,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1636086326770,"user":{"displayName":"Jack xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNUlNXY1CX3VYFSRl25LPymi5g8mOLu96mwvQm=s64","userId":"14262939990159303181"},"user_tz":300},"id":"GfLd7gFCYd1B"},"outputs":[],"source":["def fix_word(comment):\n","    \n","   # nword = re.sub(r\"@\\S+\", \" \", comment)  \n","    nword = re.sub(r\"[^a-zA-Z]\", \" \", comment)  \n","    nword = nword.lower() \n","    nword = nword.split()\n","    final_word = [i for i in nword if i not in stopwords.words('english')]\n","    final_sentence = [creat_sentance.lemmatize(z) for z in final_word]\n","    final_sentence = ' '.join(final_sentence)\n","    return final_sentence"]},{"cell_type":"code","execution_count":77,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":301,"status":"ok","timestamp":1636086912619,"user":{"displayName":"Jack xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNUlNXY1CX3VYFSRl25LPymi5g8mOLu96mwvQm=s64","userId":"14262939990159303181"},"user_tz":300},"id":"puzuynXF3Ur0","outputId":"65a50809-f47b-4fe2-abcd-97ae9b802585"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fold_id</th>\n","      <th>cv_tag</th>\n","      <th>html_id</th>\n","      <th>sent_id</th>\n","      <th>text</th>\n","      <th>tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>225</th>\n","      <td>0</td>\n","      <td>cv034</td>\n","      <td>29647</td>\n","      <td>20</td>\n","      <td>i also could have done with less of the taylor...</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>488</th>\n","      <td>0</td>\n","      <td>cv042</td>\n","      <td>10982</td>\n","      <td>35</td>\n","      <td>in this movie , as in awakenings , there comes...</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>306</th>\n","      <td>0</td>\n","      <td>cv037</td>\n","      <td>18510</td>\n","      <td>24</td>\n","      <td>if it lacks in plot and in acting it makes up ...</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>724</th>\n","      <td>0</td>\n","      <td>cv049</td>\n","      <td>20471</td>\n","      <td>20</td>\n","      <td>yeah there were some in the first half but not...</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>833</th>\n","      <td>0</td>\n","      <td>cv053</td>\n","      <td>21822</td>\n","      <td>41</td>\n","      <td>in the near future , india and pakistan may la...</td>\n","      <td>pos</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     fold_id cv_tag  html_id  sent_id  \\\n","225        0  cv034    29647       20   \n","488        0  cv042    10982       35   \n","306        0  cv037    18510       24   \n","724        0  cv049    20471       20   \n","833        0  cv053    21822       41   \n","\n","                                                  text  tag  \n","225  i also could have done with less of the taylor...  pos  \n","488  in this movie , as in awakenings , there comes...  pos  \n","306  if it lacks in plot and in acting it makes up ...  pos  \n","724  yeah there were some in the first half but not...  pos  \n","833  in the near future , india and pakistan may la...  pos  "]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["dataset = pd.read_csv('movie_review_short.csv',)\n","\n","dataset = shuffle(dataset)\n","dataset.head()"]},{"cell_type":"code","execution_count":78,"metadata":{"colab":{"background_save":true},"id":"yFa8YrBc4fSq"},"outputs":[{"name":"stdout","output_type":"stream","text":["225    pos\n","488    pos\n","306    pos\n","724    pos\n","833    pos\n","      ... \n","530    pos\n","77     pos\n","602    pos\n","275    pos\n","26     pos\n","Name: tag, Length: 898, dtype: object\n"]}],"source":["x = dataset.text.apply(fix_word)\n","y = dataset['tag']\n","print(y)"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[],"source":["vectorizer=CountVectorizer() #Encode as integers to be used for the algorithm\n","x_vectorized=vectorizer.fit_transform(x) #Learn the vocabulary dictionary and return document-term matrix."]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[],"source":["#Split between train and test data\n","from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test= train_test_split(x_vectorized, y, test_size=0.3, random_state=0)"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[],"source":["#Using decision tree\n","from sklearn.tree import DecisionTreeClassifier\n","dt=DecisionTreeClassifier(criterion='gini')\n","dt.fit(x_train, y_train)\n","prediction1=dt.predict(x_test)"]},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[],"source":["#K Neighbors Classifer\n","from sklearn.neighbors import KNeighborsClassifier\n","KNN= KNeighborsClassifier(n_neighbors=3)\n","KNN.fit(x_train, y_train)\n","prediction2=KNN.predict(x_test)"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[],"source":["#Neural network\n","from sklearn.neural_network import MLPClassifier\n","NN=MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n","NN.fit(x_train, y_train)\n","prediction3=NN.predict(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"project1.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}
